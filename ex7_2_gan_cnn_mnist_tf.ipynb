{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ex7_2_gan_cnn_mnist_tf",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youngchul-sung/three-minutes-keras/blob/master/ex7_2_gan_cnn_mnist_tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dV220eHlKJF1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2f6dcdbf-7142-4d6d-df39-8dff0c1dda6d"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "import math\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import models, layers, optimizers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Dense, Conv1D, Reshape, Flatten, Lambda\n",
        "\n",
        "\n",
        "keras.backend.set_image_data_format('channels_first')\n",
        "print(keras.backend.image_data_format)\n",
        "\n",
        "################################\n",
        "# GAN 모델링\n",
        "################################\n",
        "\n",
        "def mse_4d(y_true, y_pred):\n",
        "    return keras.backend.mean(keras.backend.square(y_pred - y_true), axis=(1,2,3))\n",
        "\n",
        "def mse_4d_tf(y_true, y_pred):\n",
        "    return tf.reduce_mean(tf.square(y_pred - y_true), axis=(1,2,3))\n",
        "\n",
        "\n",
        "class GAN(models.Sequential):\n",
        "    def __init__(self, input_dim=64):\n",
        "        \"\"\"\n",
        "        self, self.generator, self.discriminator are all models\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "\n",
        "        self.generator = self.GENERATOR()\n",
        "        self.discriminator = self.DISCRIMINATOR()\n",
        "        self.add(self.generator)\n",
        "        self.discriminator.trainable = False\n",
        "        self.add(self.discriminator)\n",
        "        \n",
        "        self.compile_all()\n",
        "\n",
        "    def GENERATOR(self):\n",
        "        input_dim = self.input_dim\n",
        "\n",
        "        model = models.Sequential()\n",
        "        model.add(layers.Dense(1024, activation='tanh', input_dim=input_dim))\n",
        "        model.add(layers.Dense(128 * 7 * 7, activation='tanh'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Reshape((128, 7, 7), input_shape=(128 * 7 * 7,)))\n",
        "        model.add(layers.UpSampling2D(size=(2, 2)))\n",
        "        model.add(layers.Conv2D(64, (5, 5), padding='same', activation='tanh'))\n",
        "        model.add(layers.UpSampling2D(size=(2, 2)))\n",
        "        model.add(layers.Conv2D(1, (5, 5), padding='same', activation='tanh'))\n",
        "        return model\n",
        "\n",
        "    def DISCRIMINATOR(self):\n",
        "        model = models.Sequential()\n",
        "        model.add(layers.Conv2D(64, (5, 5), padding='same', activation='tanh',\n",
        "                                input_shape=(1, 28, 28)))\n",
        "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(layers.Conv2D(128, (5, 5), activation='tanh'))\n",
        "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(layers.Flatten())\n",
        "        model.add(layers.Dense(1024, activation='tanh'))\n",
        "        model.add(layers.Dense(1, activation='sigmoid'))\n",
        "        return model\n",
        "\n",
        "    def compile_all(self):\n",
        "        # Compiling stage\n",
        "        d_optim = optimizers.SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
        "        g_optim = optimizers.SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
        "        self.generator.compile(loss=mse_4d_tf, optimizer=\"SGD\")\n",
        "        self.compile(loss='binary_crossentropy', optimizer=g_optim)\n",
        "        self.discriminator.trainable = True\n",
        "        self.discriminator.compile(loss='binary_crossentropy', optimizer=d_optim)\n",
        "\n",
        "    def get_z(self, ln):\n",
        "        input_dim = self.input_dim\n",
        "        return np.random.uniform(-1, 1, (ln, input_dim))\n",
        "\n",
        "    def train_both(self, x):\n",
        "        ln = x.shape[0]\n",
        "        # First trial for training discriminator\n",
        "        z = self.get_z(ln)\n",
        "        w = self.generator.predict(z, verbose=0)\n",
        "        xw = np.concatenate((x, w))\n",
        "        y2 = np.array([1] * ln + [0] * ln)\n",
        "        d_loss = self.discriminator.train_on_batch(xw, y2)\n",
        "\n",
        "        # Second trial for training generator\n",
        "        z = self.get_z(ln)\n",
        "        self.discriminator.trainable = False\n",
        "        g_loss = self.train_on_batch(z, np.array([1] * ln))\n",
        "        self.discriminator.trainable = True\n",
        "\n",
        "        return d_loss, g_loss\n",
        "\n",
        "\n",
        "################################\n",
        "# GAN 학습하기\n",
        "################################\n",
        "def combine_images(generated_images):\n",
        "    num = generated_images.shape[0]\n",
        "    width = int(math.sqrt(num))\n",
        "    height = int(math.ceil(float(num) / width))\n",
        "    shape = generated_images.shape[2:]\n",
        "    image = np.zeros((height * shape[0], width * shape[1]),\n",
        "                     dtype=generated_images.dtype)\n",
        "    for index, img in enumerate(generated_images):\n",
        "        i = int(index / width)\n",
        "        j = index % width\n",
        "        image[i * shape[0]:(i + 1) * shape[0],\n",
        "        j * shape[1]:(j + 1) * shape[1]] = img[0, :, :]\n",
        "    return image\n",
        "\n",
        "\n",
        "def get_x(X_train, index, BATCH_SIZE):\n",
        "    return X_train[index * BATCH_SIZE:(index + 1) * BATCH_SIZE]\n",
        "\n",
        "\n",
        "def save_images(generated_images, output_fold, epoch, index):\n",
        "    image = combine_images(generated_images)\n",
        "    image = image * 127.5 + 127.5\n",
        "    Image.fromarray(image.astype(np.uint8)).save(\n",
        "        output_fold + '/' +\n",
        "        str(epoch) + \"_\" + str(index) + \".png\")\n",
        "\n",
        "\n",
        "def load_data(n_train):\n",
        "    (X_train, y_train), (_, _) = mnist.load_data()\n",
        "\n",
        "    return X_train[:n_train]\n",
        "\n",
        "\n",
        "def train(args):\n",
        "    BATCH_SIZE = args.batch_size\n",
        "    epochs = args.epochs\n",
        "    output_fold = args.output_fold\n",
        "    input_dim = args.input_dim\n",
        "    n_train = args.n_train\n",
        "\n",
        "    os.makedirs(output_fold, exist_ok=True)\n",
        "    print('Output_fold is', output_fold)\n",
        "\n",
        "    X_train = load_data(n_train)\n",
        "\n",
        "    X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
        "    X_train = X_train.reshape((X_train.shape[0], 1) + X_train.shape[1:])\n",
        "\n",
        "    gan = GAN(input_dim)\n",
        "\n",
        "    d_loss_ll = []\n",
        "    g_loss_ll = []\n",
        "    for epoch in range(epochs):\n",
        "        if epoch % 100 == 0:\n",
        "            print(\"Epoch is\", epoch)\n",
        "            print(\"Number of batches\", int(X_train.shape[0] / BATCH_SIZE))\n",
        "\n",
        "        d_loss_l = []\n",
        "        g_loss_l = []\n",
        "        for index in range(int(X_train.shape[0] / BATCH_SIZE)):\n",
        "            x = get_x(X_train, index, BATCH_SIZE)\n",
        "\n",
        "            d_loss, g_loss = gan.train_both(x)\n",
        "\n",
        "            d_loss_l.append(d_loss)\n",
        "            g_loss_l.append(g_loss)\n",
        "\n",
        "        if epoch % 10 == 0 or epoch == epochs - 1:\n",
        "            z = gan.get_z(x.shape[0])\n",
        "            w = gan.generator.predict(z, verbose=0)\n",
        "            save_images(w, output_fold, epoch, 0)\n",
        "\n",
        "        d_loss_ll.append(d_loss_l)\n",
        "        g_loss_ll.append(g_loss_l)\n",
        "\n",
        "    gan.summary()\n",
        "    gan.generator.summary()\n",
        "    gan.discriminator.summary()\n",
        "\n",
        "    gan.generator.save_weights(output_fold + '/' + 'generator', True)\n",
        "    gan.discriminator.save_weights(output_fold + '/' + 'discriminator', True)\n",
        "\n",
        "    np.savetxt(output_fold + '/' + 'd_loss', d_loss_ll)\n",
        "    np.savetxt(output_fold + '/' + 'g_loss', g_loss_ll)\n",
        "\n",
        "\n",
        "################################\n",
        "# GAN 예제 실행하기\n",
        "################################\n",
        "\n",
        "class ARGS:\n",
        "    def __init__(self):\n",
        "        self.batch_size = 16\n",
        "        self.epochs = 1000\n",
        "        self.output_fold = 'GAN_OUT'\n",
        "        self.input_dim = 10\n",
        "        self.n_train = 32\n",
        "\n",
        "def main():\n",
        "    args = ARGS()\n",
        "    train(args)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<function image_data_format at 0x7f2fcef1e8c8>\n",
            "Output_fold is GAN_OUT\n",
            "Epoch is 0\n",
            "Number of batches 2\n",
            "Epoch is 100\n",
            "Number of batches 2\n",
            "Epoch is 200\n",
            "Number of batches 2\n",
            "Epoch is 300\n",
            "Number of batches 2\n",
            "Epoch is 400\n",
            "Number of batches 2\n",
            "Epoch is 500\n",
            "Number of batches 2\n",
            "Epoch is 600\n",
            "Number of batches 2\n",
            "Epoch is 700\n",
            "Number of batches 2\n",
            "Epoch is 800\n",
            "Number of batches 2\n",
            "Epoch is 900\n",
            "Number of batches 2\n",
            "Model: \"gan_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_8 (Sequential)    (None, 1, 28, 28)         6671617   \n",
            "_________________________________________________________________\n",
            "sequential_9 (Sequential)    (None, 1)                 3485441   \n",
            "=================================================================\n",
            "Total params: 6,671,617\n",
            "Trainable params: 6,659,073\n",
            "Non-trainable params: 12,544\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_16 (Dense)             (None, 1024)              11264     \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 6272)              6428800   \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 6272)              25088     \n",
            "_________________________________________________________________\n",
            "reshape_4 (Reshape)          (None, 128, 7, 7)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_8 (UpSampling2 (None, 128, 14, 14)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 64, 14, 14)        204864    \n",
            "_________________________________________________________________\n",
            "up_sampling2d_9 (UpSampling2 (None, 64, 28, 28)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 1, 28, 28)         1601      \n",
            "=================================================================\n",
            "Total params: 6,671,617\n",
            "Trainable params: 6,659,073\n",
            "Non-trainable params: 12,544\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_18 (Conv2D)           (None, 64, 28, 28)        1664      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 64, 14, 14)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 128, 10, 10)       204928    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 128, 5, 5)         0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 3200)              0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 1024)              3277824   \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 1)                 1025      \n",
            "=================================================================\n",
            "Total params: 3,485,441\n",
            "Trainable params: 3,485,441\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}